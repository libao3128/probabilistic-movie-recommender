{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"eval_framework\")))\n",
        "\n",
        "from data_loader import load_data, split_data\n",
        "import reporter \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DaF-2al9uKov"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-leAbIkNuNGL"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_mac(sample_size=None):\n",
        "    \"\"\"Load MovieLens dataset\"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    print(\"Loading MovieLens 100K dataset...\")\n",
        "    \n",
        "    # Load ratings\n",
        "    ratings = pd.read_csv('../data/ml-latest-small/ml-latest-small/ratings.csv')\n",
        "    \n",
        "    # Load movies\n",
        "    movies = pd.read_csv('../data/ml-latest-small/ml-latest-small/movies.csv')\n",
        "    \n",
        "    \n",
        "    # Convert genres to list format\n",
        "    movies['genres'] = movies['genres'].str.split('|')\n",
        "    movies = movies[['movieId', 'title', 'genres']]\n",
        "    \n",
        "    if sample_size:\n",
        "        # Sample users\n",
        "        unique_users = ratings['userId'].unique()\n",
        "        sampled_users = np.random.choice(unique_users, size=sample_size, replace=False)\n",
        "        ratings = ratings[ratings['userId'].isin(sampled_users)]\n",
        "        movies = movies[movies['movieId'].isin(ratings['movieId'].unique())]\n",
        "    \n",
        "    print(f\"Loaded {len(ratings)} ratings and {len(movies)} movies\")\n",
        "    return ratings, movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/angela/Desktop/probabilistic-movie-recommender/SPN\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9FK841ieQ1iV",
        "outputId": "9f9a5052-d433-4fd1-886a-69722cf7710c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Loading MovieLens 100K dataset...\n",
            "Loaded 100836 ratings and 9742 movies\n"
          ]
        }
      ],
      "source": [
        "ratings, movies = load_data_mac()\n",
        "\n",
        "# Encode movieId in both datasets\n",
        "movie_encoder = LabelEncoder()\n",
        "movies[\"movieId\"] = movie_encoder.fit_transform(movies[\"movieId\"])\n",
        "ratings[\"movieId\"] = movie_encoder.transform(ratings[\"movieId\"])\n",
        "\n",
        "# Merge genres with ratings\n",
        "df = ratings.merge(movies[[\"movieId\", \"genres\"]], on=\"movieId\", how=\"left\")\n",
        "df_expanded = df[\"genres\"].str.get_dummies(sep=\"|\")\n",
        "df = pd.concat([df.drop(columns=[\"genres\"]), df_expanded], axis=1)\n",
        "\n",
        "# Binarize rating to create label\n",
        "df[\"rating_class\"] = (df[\"rating\"] >= 4).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dimensionality reduction on genre using PCA\n",
        "genre_columns = df_expanded.columns.tolist()\n",
        "scaler = StandardScaler()\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "scaled_genres = scaler.fit_transform(df[genre_columns])\n",
        "pca_genres = pca.fit_transform(scaled_genres)\n",
        "\n",
        "pca_columns = [f\"pca_genre_{i}\" for i in range(pca_genres.shape[1])]\n",
        "df_pca = pd.DataFrame(pca_genres, columns=pca_columns)\n",
        "df = pd.concat([df.drop(columns=genre_columns), df_pca], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1q-wzOuugb3"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHrbblxMQ1iW",
        "outputId": "c6286210-4c6d-407b-90af-054bee6a44c4"
      },
      "outputs": [],
      "source": [
        "from spn.structure.Base import Context\n",
        "from spn.structure.StatisticalTypes import MetaType\n",
        "from spn.algorithms.LearningWrappers import learn_classifier\n",
        "from spn.structure.leaves.parametric.Parametric import Categorical, Gaussian\n",
        "from spn.algorithms.LearningWrappers import learn_parametric\n",
        "import scipy\n",
        "scipy.NINF = float(\"-inf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nSplitting data...\n",
            "Training set size: 80668, Test set size: 20168\n",
            "Runtime: 182.7926 seconds\n",
            "Memory peak: 4258.97 MiB\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from memory_profiler import memory_usage\n",
        "feature_columns = [\"userId\", \"movieId\"] + pca_columns\n",
        "X = df[feature_columns].values.astype(float)\n",
        "y = df[[\"rating_class\"]].values.astype(float)\n",
        "data = np.concatenate([X, y], axis=1)\n",
        "train_data, test_data = split_data(data)\n",
        "\n",
        "# Define SPN context\n",
        "param_types = [Categorical, Categorical] + [Gaussian] * len(pca_columns) + [Categorical]\n",
        "context = Context(parametric_types=param_types)\n",
        "context.add_domains(train_data)\n",
        "\n",
        "\n",
        "def train():\n",
        "    start = time.time()\n",
        "    # Learn SPN classifier\n",
        "    spn = learn_classifier(train_data, context, spn_learn_wrapper=learn_parametric, label_idx=train_data.shape[1] - 1)\n",
        "    end = time.time()\n",
        "    return spn, end - start\n",
        "\n",
        "mem_usage, (spn, runtime) = memory_usage(train, retval=True, max_iterations=1)\n",
        "print(f\"Runtime: {runtime:.4f} seconds\")\n",
        "print(f\"Memory peak: {max(mem_usage) - min(mem_usage):.2f} MiB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference time: 1.36 s\n",
            "\n",
            "===== SPN Classification Report =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.69      0.68     10477\n",
            "           1       0.66      0.64      0.65      9691\n",
            "\n",
            "    accuracy                           0.67     20168\n",
            "   macro avg       0.67      0.66      0.66     20168\n",
            "weighted avg       0.67      0.67      0.67     20168\n",
            "\n",
            "Accuracy: 0.6659\n"
          ]
        }
      ],
      "source": [
        "from spn.algorithms.MPE import mpe\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "start = time.time()\n",
        "mpe_input = test_data.copy()\n",
        "mpe_input[:, -1] = np.nan\n",
        "predictions = mpe(spn, mpe_input)\n",
        "end = time.time()\n",
        "print(f\"Inference time: {end - start:.2f} s\")\n",
        "pred_classes = predictions[:, -1]\n",
        "\n",
        "y_true = test_data[:, -1].astype(int)\n",
        "y_pred = predictions[:, -1].astype(int)\n",
        "\n",
        "print(\"\\n===== SPN Classification Report =====\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.5780\n",
            "MAE:  0.3341\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE:  {mae:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
