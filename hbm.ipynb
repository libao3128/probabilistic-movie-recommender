{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d112c38",
   "metadata": {},
   "source": [
    "# HBM\n",
    "## Reference\n",
    "- [Efficient bayesian hierarchical user modeling for recommendation system](https://doi.org/10.1145/1277741.1277752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e96573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pytensor.tensor as pt\n",
    "from PMF.LoadData import load_rating_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9db761",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78cabfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'data\\ml-latest-small\\ml-latest-small'\n",
    "ratings = pd.read_csv(dataset_path + r'\\ratings.csv')\n",
    "movies = pd.read_csv(dataset_path + r'\\movies.csv')\n",
    "tags = pd.read_csv(dataset_path + r'\\tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeeaf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings = load_rating_data(r'data\\ml-100k\\ml-100k\\u.data')\n",
    "#ratings = pd.DataFrame(ratings, columns=['user_id', 'item_id', 'rating'])\n",
    "#movies = pd.read_csv(r'data\\ml-100k\\ml-100k\\u.item', sep='|', encoding='latin-1', header=None)\n",
    "#movies.columns = ['item_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown',\n",
    "#                  'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary',\n",
    "#                  'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',\n",
    "#                  'Sci-Fi', 'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab388d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84cf4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = movies.shape[0]\n",
    "num_users = ratings['userId'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e64857d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba3c1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Adventure, Animation, Children, Comedy, Fantasy]\n",
       "1                          [Adventure, Children, Fantasy]\n",
       "2                                       [Comedy, Romance]\n",
       "3                                [Comedy, Drama, Romance]\n",
       "4                                                [Comedy]\n",
       "                              ...                        \n",
       "9737                 [Action, Animation, Comedy, Fantasy]\n",
       "9738                         [Animation, Comedy, Fantasy]\n",
       "9739                                              [Drama]\n",
       "9740                                  [Action, Animation]\n",
       "9741                                             [Comedy]\n",
       "Name: genres, Length: 9742, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09406e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "327a058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.barplot(data=genre_df, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7785c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9703ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreHBMRecommender:\n",
    "    def __init__(self, ratings_df, movies_df, latent_dim=10):\n",
    "        \"\"\"\n",
    "        ratings_df: DataFrame with columns ['userId', 'movieId', 'rating']\n",
    "        movies_df:  DataFrame with columns ['movieId', 'genres']\n",
    "\n",
    "        \"\"\"\n",
    "        self.ratings_df = ratings_df.copy()\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = None\n",
    "        self.trace = None\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "        self._preprocess()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        \"\"\"Map userId and movieId to 0-based indices\"\"\"\n",
    "        self.user_map = {uid: i for i, uid in enumerate(self.ratings_df['userId'].unique())}\n",
    "        self.movie_map = {mid: i for i, mid in enumerate(self.movies_df['movieId'].unique())}\n",
    "\n",
    "        self.ratings_df['uidx'] = self.ratings_df['userId'].map(self.user_map)\n",
    "        self.ratings_df['midx'] = self.ratings_df['movieId'].map(self.movie_map)\n",
    "\n",
    "        self.num_users = len(self.user_map)\n",
    "        self.num_movies = len(self.movie_map)\n",
    "        \n",
    "        genre_onehot = self.mlb.fit_transform(movies['genres'])\n",
    "\n",
    "        # 建立對應欄位名稱\n",
    "        genre_df = pd.DataFrame(genre_onehot, columns=self.mlb.classes_)\n",
    "        self.genre_map = {genre: i for i, genre in enumerate(self.mlb.classes_)}\n",
    "        self.genre_idx_list = genre_df.apply(lambda x: [self.genre_map[g] for g in x.index[x == 1].tolist()], axis=1).to_list()\n",
    "\n",
    "    def _build_mu_i(self, mu_g):\n",
    "        \"\"\"Build per-movie prior mean vector mu_i based on genre index list\"\"\"\n",
    "        mu_i_list = []\n",
    "        for genre_idxs in self.genre_idx_list:\n",
    "            mu_mean = pm.math.mean(mu_g[genre_idxs], axis=0)\n",
    "            mu_i_list.append(mu_mean)\n",
    "        return pm.math.stack(mu_i_list, axis=0)\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Construct the PyMC model\"\"\"\n",
    "        print(\"Building model...\")\n",
    "        user_idx = self.ratings_df['uidx'].values\n",
    "        movie_idx = self.ratings_df['midx'].values\n",
    "        ratings = self.ratings_df['rating'].values\n",
    "        num_genres = len(self.mlb.classes_)\n",
    "        print(f\"Number of genres: {num_genres}\")\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            mu_g = pm.Normal(\"mu_g\", mu=0, sigma=1, shape=(num_genres, self.latent_dim))\n",
    "            print(f\"mu_g shape: {mu_g.shape}\")\n",
    "            sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "            \n",
    "\n",
    "            mu_i = self._build_mu_i(mu_g)\n",
    "            x_movie = pm.Normal(\"x_movie\", mu=mu_i, sigma=sigma, shape=(self.num_movies, self.latent_dim))\n",
    "            print(f\"x_movie shape: {x_movie.shape}\")\n",
    "            w_user = pm.Normal(\"w_user\", mu=0, sigma=1, shape=(self.num_users, self.latent_dim))\n",
    "            print(f\"w_user shape: {w_user.shape}\")\n",
    "\n",
    "            pred = pm.math.sum(w_user[user_idx] * x_movie[movie_idx], axis=1)\n",
    "            print(f\"pred shape: {pred.shape}\")\n",
    "            r = pm.Normal(\"r\", mu=pred, sigma=0.5, observed=ratings)\n",
    "\n",
    "            self.model = model\n",
    "        print(\"Model built successfully.\")\n",
    "        \n",
    "    def fit(self, draws=1000, tune=500, target_accept=0.9):\n",
    "        \"\"\"Run MCMC sampling\"\"\"\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "        print(\"Fitting model...\")\n",
    "        with self.model:\n",
    "            self.trace = pm.sample(draws=draws, tune=tune, target_accept=target_accept, progressbar=True)\n",
    "\n",
    "            #approx = pm.fit(method='advi', n=10000)\n",
    "            #trace = approx.sample(500)\n",
    "\n",
    "            \n",
    "    def predict(self, user_id, movie_id):\n",
    "        \"\"\"\n",
    "        根據 user_id 與 movie_id 預測評分（使用後驗平均潛在向量）\n",
    "        \"\"\"\n",
    "        if self.trace is None:\n",
    "            raise ValueError(\"Model not fitted yet. Call fit() first.\")\n",
    "        if user_id not in self.user_map or movie_id not in self.movie_map:\n",
    "            raise ValueError(\"user_id 或 movie_id 不在訓練資料中\")\n",
    "\n",
    "        # 對應 index\n",
    "        u_idx = self.user_map[user_id]\n",
    "        m_idx = self.movie_map[movie_id]\n",
    "\n",
    "        # 後驗平均向量\n",
    "        w_user = self.trace.posterior['w_user'].mean(dim=(\"chain\", \"draw\")).values\n",
    "        x_movie = self.trace.posterior['x_movie'].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "        # 預測值 = 內積\n",
    "        return float(np.dot(w_user[u_idx], x_movie[m_idx]))\n",
    "\n",
    "    def get_posterior_means(self):\n",
    "        \"\"\"Extract MAP estimate of user and movie vectors\"\"\"\n",
    "        assert self.trace is not None, \"You must call fit() first.\"\n",
    "        w_user = self.trace.posterior['w_user'].mean(dim=(\"chain\", \"draw\")).values\n",
    "        x_movie = self.trace.posterior['x_movie'].mean(dim=(\"chain\", \"draw\")).values\n",
    "        return w_user, x_movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ab210ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenreHBMRecommender(ratings, movies, latent_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "062d71cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Number of genres: 20\n",
      "mu_g shape: Shape.0\n",
      "x_movie shape: Shape.0\n",
      "w_user shape: Shape.0\n",
      "pred shape: Shape.0\n",
      "Model built successfully.\n",
      "Fitting model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.fit(\u001b[32m100\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m0.9\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mGenreHBMRecommender.fit\u001b[39m\u001b[34m(self, draws, tune, target_accept)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28mself\u001b[39m.trace = pm.sample(draws=draws, tune=tune, target_accept=target_accept, progressbar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:789\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[39m\n\u001b[32m    786\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdraws\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples per chain. Reliable r-hat and ESS diagnostics require longer chains for accurate estimate.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    787\u001b[39m     _log.warning(msg)\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m provided_steps, selected_steps = assign_step_methods(model, step, methods=pm.STEP_METHODS)\n\u001b[32m    790\u001b[39m exclusive_nuts = (\n\u001b[32m    791\u001b[39m     \u001b[38;5;66;03m# User provided an instantiated NUTS step, and nothing else is needed\u001b[39;00m\n\u001b[32m    792\u001b[39m     (\u001b[38;5;129;01mnot\u001b[39;00m selected_steps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(provided_steps) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(provided_steps[\u001b[32m0\u001b[39m], NUTS))\n\u001b[32m   (...)\u001b[39m\u001b[32m    799\u001b[39m     )\n\u001b[32m    800\u001b[39m )\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler != \u001b[33m\"\u001b[39m\u001b[33mpymc\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:247\u001b[39m, in \u001b[36massign_step_methods\u001b[39m\u001b[34m(model, step, methods)\u001b[39m\n\u001b[32m    245\u001b[39m methods_list: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[BlockedStep]] = \u001b[38;5;28mlist\u001b[39m(methods \u001b[38;5;129;01mor\u001b[39;00m pm.STEP_METHODS)\n\u001b[32m    246\u001b[39m selected_steps: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m[BlockedStep], \u001b[38;5;28mlist\u001b[39m] = {}\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m model_logp = model.logp()\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model.value_vars:\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m assigned_vars:\n\u001b[32m    251\u001b[39m         \u001b[38;5;66;03m# determine if a gradient can be computed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\model\\core.py:696\u001b[39m, in \u001b[36mModel.logp\u001b[39m\u001b[34m(self, vars, jacobian, sum)\u001b[39m\n\u001b[32m    694\u001b[39m rv_logps: \u001b[38;5;28mlist\u001b[39m[TensorVariable] = []\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rvs:\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m     rv_logps = transformed_conditional_logp(\n\u001b[32m    697\u001b[39m         rvs=rvs,\n\u001b[32m    698\u001b[39m         rvs_to_values=\u001b[38;5;28mself\u001b[39m.rvs_to_values,\n\u001b[32m    699\u001b[39m         rvs_to_transforms=\u001b[38;5;28mself\u001b[39m.rvs_to_transforms,\n\u001b[32m    700\u001b[39m         jacobian=jacobian,\n\u001b[32m    701\u001b[39m     )\n\u001b[32m    702\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rv_logps, \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    704\u001b[39m \u001b[38;5;66;03m# Replace random variables by their value variables in potential terms\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\logprob\\basic.py:595\u001b[39m, in \u001b[36mtransformed_conditional_logp\u001b[39m\u001b[34m(rvs, rvs_to_values, rvs_to_transforms, jacobian, **kwargs)\u001b[39m\n\u001b[32m    592\u001b[39m     transform_rewrite = TransformValuesRewrite(values_to_transforms)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    594\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mwarn_rvs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m temp_logp_terms = conditional_logp(\n\u001b[32m    596\u001b[39m     rvs_to_values,\n\u001b[32m    597\u001b[39m     extra_rewrites=transform_rewrite,\n\u001b[32m    598\u001b[39m     use_jacobian=jacobian,\n\u001b[32m    599\u001b[39m     **kwargs,\n\u001b[32m    600\u001b[39m )\n\u001b[32m    602\u001b[39m \u001b[38;5;66;03m# The function returns the logp for every single value term we provided to it.\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# This includes the extra values we plugged in above, so we filter those we\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[38;5;66;03m# actually wanted in the same order they were given in.\u001b[39;00m\n\u001b[32m    605\u001b[39m logp_terms = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\logprob\\basic.py:479\u001b[39m, in \u001b[36mconditional_logp\u001b[39m\u001b[34m(rv_values, warn_rvs, ir_rewriter, extra_rewrites, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Create a map between variables and conditional logps such that the sum is their joint logp.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m    419\u001b[39m \u001b[33;03mThe `rv_values` dictionary specifies a joint probability graph defined by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    475\u001b[39m \n\u001b[32m    476\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    477\u001b[39m warn_rvs, kwargs = _deprecate_warn_missing_rvs(warn_rvs, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m fgraph = construct_ir_fgraph(rv_values, ir_rewriter=ir_rewriter)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_rewrites \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    482\u001b[39m     extra_rewrites.rewrite(fgraph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pymc\\logprob\\rewriting.py:254\u001b[39m, in \u001b[36mconstruct_ir_fgraph\u001b[39m\u001b[34m(rv_values, ir_rewriter)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ir_rewriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    253\u001b[39m     ir_rewriter = logprob_rewrites_db.query(RewriteDatabaseQuery(include=[\u001b[33m\"\u001b[39m\u001b[33mbasic\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m ir_rewriter.rewrite(fgraph)\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Reintroduce original value variables\u001b[39;00m\n\u001b[32m    257\u001b[39m replacements = \u001b[38;5;28mtuple\u001b[39m((cloned_v, v) \u001b[38;5;28;01mfor\u001b[39;00m v, cloned_v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(rv_values.values(), cloned_values))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:120\u001b[39m, in \u001b[36mGraphRewriter.rewrite\u001b[39m\u001b[34m(self, fgraph, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    112\u001b[39m \n\u001b[32m    113\u001b[39m \u001b[33;03mThis is meant as a shortcut for the following::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.add_requirements(fgraph)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(fgraph, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:292\u001b[39m, in \u001b[36mSequentialGraphRewriter.apply\u001b[39m\u001b[34m(self, fgraph)\u001b[39m\n\u001b[32m    290\u001b[39m nb_nodes_before = \u001b[38;5;28mlen\u001b[39m(fgraph.apply_nodes)\n\u001b[32m    291\u001b[39m t0 = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m sub_prof = rewriter.apply(fgraph)\n\u001b[32m    293\u001b[39m l.append(\u001b[38;5;28mfloat\u001b[39m(time.perf_counter() - t0))\n\u001b[32m    294\u001b[39m sub_profs.append(sub_prof)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:292\u001b[39m, in \u001b[36mSequentialGraphRewriter.apply\u001b[39m\u001b[34m(self, fgraph)\u001b[39m\n\u001b[32m    290\u001b[39m nb_nodes_before = \u001b[38;5;28mlen\u001b[39m(fgraph.apply_nodes)\n\u001b[32m    291\u001b[39m t0 = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m sub_prof = rewriter.apply(fgraph)\n\u001b[32m    293\u001b[39m l.append(\u001b[38;5;28mfloat\u001b[39m(time.perf_counter() - t0))\n\u001b[32m    294\u001b[39m sub_profs.append(sub_prof)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:2392\u001b[39m, in \u001b[36mEquilibriumGraphRewriter.apply\u001b[39m\u001b[34m(self, fgraph, start_from)\u001b[39m\n\u001b[32m   2388\u001b[39m global_sub_profs.append(sub_profs)\n\u001b[32m   2390\u001b[39m global_rewriter_timing.append(\u001b[38;5;28mfloat\u001b[39m(time.perf_counter() - t0))\n\u001b[32m-> \u001b[39m\u001b[32m2392\u001b[39m changed |= apply_cleanup(iter_cleanup_sub_profs)\n\u001b[32m   2394\u001b[39m topo_t0 = time.perf_counter()\n\u001b[32m   2395\u001b[39m q = deque(io_toposort(fgraph.inputs, start_from))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:2351\u001b[39m, in \u001b[36mEquilibriumGraphRewriter.apply.<locals>.apply_cleanup\u001b[39m\u001b[34m(profs_dict)\u001b[39m\n\u001b[32m   2349\u001b[39m nb = change_tracker.nb_imported\n\u001b[32m   2350\u001b[39m t_rewrite = time.perf_counter()\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m sub_prof = crewriter.apply(fgraph)\n\u001b[32m   2352\u001b[39m time_rewriters[crewriter] += time.perf_counter() - t_rewrite\n\u001b[32m   2353\u001b[39m profs_dict[crewriter].append(sub_prof)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:772\u001b[39m, in \u001b[36mMergeOptimizer.apply\u001b[39m\u001b[34m(self, fgraph)\u001b[39m\n\u001b[32m    770\u001b[39m         fgraph.replace_all(pairs, reason=\u001b[33m\"\u001b[39m\u001b[33mMergeOptimizer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m         fgraph.replace_all_validate(pairs, reason=\u001b[33m\"\u001b[39m\u001b[33mMergeOptimizer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InconsistencyError:\n\u001b[32m    774\u001b[39m     success = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\features.py:579\u001b[39m, in \u001b[36mReplaceValidate.replace_all_validate\u001b[39m\u001b[34m(self, fgraph, replacements, reason, verbose, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r, new_r \u001b[38;5;129;01min\u001b[39;00m replacements:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m         fgraph.replace(r, new_r, reason=reason, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs)\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    581\u001b[39m         msg = \u001b[38;5;28mstr\u001b[39m(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\fg.py:535\u001b[39m, in \u001b[36mFunctionGraph.replace\u001b[39m\u001b[34m(self, var, new_var, reason, verbose, import_missing)\u001b[39m\n\u001b[32m    528\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    529\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe replacement variable has a test value with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33ma shape different from the original variable\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest value. Original: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtval_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, new: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_tval_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    532\u001b[39m             )\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.clients[var]):\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28mself\u001b[39m.change_node_input(\n\u001b[32m    536\u001b[39m         node, i, new_var, reason=reason, import_missing=import_missing\n\u001b[32m    537\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\fg.py:462\u001b[39m, in \u001b[36mFunctionGraph.change_node_input\u001b[39m\u001b[34m(self, node, i, new_var, reason, import_missing, check)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28mself\u001b[39m.remove_client(r, (node, i), reason=reason)\n\u001b[32m    459\u001b[39m \u001b[38;5;66;03m# Precondition: the substitution is semantically valid However it may\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;66;03m# introduce cycles to the graph, in which case the transaction will be\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;66;03m# reverted later.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m \u001b[38;5;28mself\u001b[39m.execute_callbacks(\u001b[33m\"\u001b[39m\u001b[33mon_change_input\u001b[39m\u001b[33m\"\u001b[39m, node, i, r, new_var, reason=reason)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\fg.py:727\u001b[39m, in \u001b[36mFunctionGraph.execute_callbacks\u001b[39m\u001b[34m(self, name, *args, **kwargs)\u001b[39m\n\u001b[32m    725\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    726\u001b[39m     tf0 = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m     fn(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    728\u001b[39m     \u001b[38;5;28mself\u001b[39m.execute_callbacks_times[feature] += time.perf_counter() - tf0\n\u001b[32m    729\u001b[39m \u001b[38;5;28mself\u001b[39m.execute_callbacks_time += time.perf_counter() - t0\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:561\u001b[39m, in \u001b[36mMergeFeature.on_change_input\u001b[39m\u001b[34m(self, fgraph, node, i, r, new_r, reason)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes_seen:\n\u001b[32m    558\u001b[39m     \u001b[38;5;66;03m# If inputs to a node change, it's not guaranteed that the node is\u001b[39;00m\n\u001b[32m    559\u001b[39m     \u001b[38;5;66;03m# distinct from the other nodes in `self.nodes_seen`.\u001b[39;00m\n\u001b[32m    560\u001b[39m     \u001b[38;5;28mself\u001b[39m.nodes_seen.discard(node)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m     \u001b[38;5;28mself\u001b[39m.process_node(fgraph, node)\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_r, AtomicVariable):\n\u001b[32m    564\u001b[39m     \u001b[38;5;28mself\u001b[39m.process_atomic(fgraph, new_r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:619\u001b[39m, in \u001b[36mMergeFeature.process_node\u001b[39m\u001b[34m(self, fgraph, node)\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node.inputs:\n\u001b[32m    612\u001b[39m     \u001b[38;5;66;03m# We use the smallest clients list.  Some `Op`s like `Elemwise`\u001b[39;00m\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# have rewrites that put constants as the first inputs.  Since\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    616\u001b[39m     \u001b[38;5;66;03m# average, so by picking the smallest clients list, we might speed\u001b[39;00m\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# things up?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     clients = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    620\u001b[39m         (fgraph.clients[inp] \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m node.inputs), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[32m    621\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(clients) > \u001b[32m0\u001b[39m\n\u001b[32m    624\u001b[39m     merge_candidates = [c \u001b[38;5;28;01mfor\u001b[39;00m c, i \u001b[38;5;129;01min\u001b[39;00m clients \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes_seen]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\.conda\\envs\\rm_sys\\Lib\\site-packages\\pytensor\\graph\\rewriting\\basic.py:620\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node.inputs:\n\u001b[32m    612\u001b[39m     \u001b[38;5;66;03m# We use the smallest clients list.  Some `Op`s like `Elemwise`\u001b[39;00m\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# have rewrites that put constants as the first inputs.  Since\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    616\u001b[39m     \u001b[38;5;66;03m# average, so by picking the smallest clients list, we might speed\u001b[39;00m\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# things up?\u001b[39;00m\n\u001b[32m    619\u001b[39m     clients = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m         (fgraph.clients[inp] \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m node.inputs), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[32m    621\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(clients) > \u001b[32m0\u001b[39m\n\u001b[32m    624\u001b[39m     merge_candidates = [c \u001b[38;5;28;01mfor\u001b[39;00m c, i \u001b[38;5;129;01min\u001b[39;00m clients \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes_seen]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(100, 50, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
